{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM924/tIDeXT72rZVZMd+mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonni0908/computer-vision-study/blob/main/VGGnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FfsqYRt-2iPN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfgs = { \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "         \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "         \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
        "         \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"] }"
      ],
      "metadata": {
        "id": "fQhulaKQ2kik"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, cfg, batch_norm, num_classes = 1000, init_weights=True, drop_p = 0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = self.make_layers(cfg)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) # 7x7이 되도록 avg pooling 하는 녀석\n",
        "        self.classifier = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(p=drop_p),\n",
        "                                        nn.Linear(4096, 4096),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(p=drop_p),\n",
        "                                        nn.Linear(4096, num_classes))\n",
        "\n",
        "        if init_weights:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\") # 합성곱 레이어의 가중치를 Kaiming Normal 초기화 방법\n",
        "                    if m.bias is not None:\n",
        "                        nn.init.constant_(m.bias, 0) # bias 초기화\n",
        "                elif isinstance(m, nn.Linear):\n",
        "                    nn.init.normal_(m.weight, 0, 0.01) #선형 레이어의 weight를 normal distribution에서 무작위로 초기화, 0은 평균, 0.01은 표준편차\n",
        "                    nn.init.constant_(m.bias, 0) # bias 초기화\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def make_layers(self, cfg, batch_norm = False):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in cfg:\n",
        "            if type(v) == int: # in면 conv\n",
        "                if batch_norm:\n",
        "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1), # list append\n",
        "                              nn.BatchNorm2d(v),\n",
        "                              nn.ReLU()]\n",
        "                else:\n",
        "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1),\n",
        "                             nn.ReLU()]\n",
        "                in_channels = v\n",
        "            else:\n",
        "                layers += [nn.MaxPool2d(2)] # string이면 pooling\n",
        "        return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "XOy7ARx72nlV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avgpool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "print(avgpool(torch.randn(2,3,32,32)).shape)\n",
        "print(avgpool(torch.randn(2,3,2,2))) # 작은 놈이 들어오면 늘려서라도 맞춰준다\n",
        "# print(avgpool(torch.randn(2,3,1,1))) # 값을 복제 시켜놓음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4fT_NwTvW9U",
        "outputId": "5ffe1a7c-76b3-4447-9e3e-a5016a20943f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4, 4])\n",
            "tensor([[[[-0.2651, -0.2651,  1.2632,  1.2632],\n",
            "          [-0.2651, -0.2651,  1.2632,  1.2632],\n",
            "          [ 0.0675,  0.0675,  0.6010,  0.6010],\n",
            "          [ 0.0675,  0.0675,  0.6010,  0.6010]],\n",
            "\n",
            "         [[-1.6959, -1.6959, -0.7545, -0.7545],\n",
            "          [-1.6959, -1.6959, -0.7545, -0.7545],\n",
            "          [ 0.2379,  0.2379, -1.2204, -1.2204],\n",
            "          [ 0.2379,  0.2379, -1.2204, -1.2204]],\n",
            "\n",
            "         [[-1.3491, -1.3491,  0.6328,  0.6328],\n",
            "          [-1.3491, -1.3491,  0.6328,  0.6328],\n",
            "          [ 0.1624,  0.1624,  0.9800,  0.9800],\n",
            "          [ 0.1624,  0.1624,  0.9800,  0.9800]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2197,  0.2197,  2.0498,  2.0498],\n",
            "          [ 0.2197,  0.2197,  2.0498,  2.0498],\n",
            "          [-0.0237, -0.0237,  1.3253,  1.3253],\n",
            "          [-0.0237, -0.0237,  1.3253,  1.3253]],\n",
            "\n",
            "         [[-0.0531, -0.0531, -0.6551, -0.6551],\n",
            "          [-0.0531, -0.0531, -0.6551, -0.6551],\n",
            "          [-1.3351, -1.3351, -0.5670, -0.5670],\n",
            "          [-1.3351, -1.3351, -0.5670, -0.5670]],\n",
            "\n",
            "         [[-0.8438, -0.8438,  2.2623,  2.2623],\n",
            "          [-0.8438, -0.8438,  2.2623,  2.2623],\n",
            "          [ 0.7065,  0.7065,  0.1992,  0.1992],\n",
            "          [ 0.7065,  0.7065,  0.1992,  0.1992]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG(cfgs[\"E\"], batch_norm=False)\n",
        "# print(model)\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "summary(model, input_size=(2,3,224,224), device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lyoaltNyzt4",
        "outputId": "ccb0a367-e1cf-4bc0-9c39-47d679882d0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG                                      [2, 1000]                 --\n",
              "├─Sequential: 1-1                        [2, 512, 7, 7]            --\n",
              "│    └─Conv2d: 2-1                       [2, 64, 224, 224]         1,792\n",
              "│    └─ReLU: 2-2                         [2, 64, 224, 224]         --\n",
              "│    └─Conv2d: 2-3                       [2, 64, 224, 224]         36,928\n",
              "│    └─ReLU: 2-4                         [2, 64, 224, 224]         --\n",
              "│    └─MaxPool2d: 2-5                    [2, 64, 112, 112]         --\n",
              "│    └─Conv2d: 2-6                       [2, 128, 112, 112]        73,856\n",
              "│    └─ReLU: 2-7                         [2, 128, 112, 112]        --\n",
              "│    └─Conv2d: 2-8                       [2, 128, 112, 112]        147,584\n",
              "│    └─ReLU: 2-9                         [2, 128, 112, 112]        --\n",
              "│    └─MaxPool2d: 2-10                   [2, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-11                      [2, 256, 56, 56]          295,168\n",
              "│    └─ReLU: 2-12                        [2, 256, 56, 56]          --\n",
              "│    └─Conv2d: 2-13                      [2, 256, 56, 56]          590,080\n",
              "│    └─ReLU: 2-14                        [2, 256, 56, 56]          --\n",
              "│    └─Conv2d: 2-15                      [2, 256, 56, 56]          590,080\n",
              "│    └─ReLU: 2-16                        [2, 256, 56, 56]          --\n",
              "│    └─Conv2d: 2-17                      [2, 256, 56, 56]          590,080\n",
              "│    └─ReLU: 2-18                        [2, 256, 56, 56]          --\n",
              "│    └─MaxPool2d: 2-19                   [2, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-20                      [2, 512, 28, 28]          1,180,160\n",
              "│    └─ReLU: 2-21                        [2, 512, 28, 28]          --\n",
              "│    └─Conv2d: 2-22                      [2, 512, 28, 28]          2,359,808\n",
              "│    └─ReLU: 2-23                        [2, 512, 28, 28]          --\n",
              "│    └─Conv2d: 2-24                      [2, 512, 28, 28]          2,359,808\n",
              "│    └─ReLU: 2-25                        [2, 512, 28, 28]          --\n",
              "│    └─Conv2d: 2-26                      [2, 512, 28, 28]          2,359,808\n",
              "│    └─ReLU: 2-27                        [2, 512, 28, 28]          --\n",
              "│    └─MaxPool2d: 2-28                   [2, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-29                      [2, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-30                        [2, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-31                      [2, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-32                        [2, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-33                      [2, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-34                        [2, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-35                      [2, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-36                        [2, 512, 14, 14]          --\n",
              "│    └─MaxPool2d: 2-37                   [2, 512, 7, 7]            --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [2, 512, 7, 7]            --\n",
              "├─Sequential: 1-3                        [2, 1000]                 --\n",
              "│    └─Linear: 2-38                      [2, 4096]                 102,764,544\n",
              "│    └─ReLU: 2-39                        [2, 4096]                 --\n",
              "│    └─Dropout: 2-40                     [2, 4096]                 --\n",
              "│    └─Linear: 2-41                      [2, 4096]                 16,781,312\n",
              "│    └─ReLU: 2-42                        [2, 4096]                 --\n",
              "│    └─Dropout: 2-43                     [2, 4096]                 --\n",
              "│    └─Linear: 2-44                      [2, 1000]                 4,097,000\n",
              "==========================================================================================\n",
              "Total params: 143,667,240\n",
              "Trainable params: 143,667,240\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 39.29\n",
              "==========================================================================================\n",
              "Input size (MB): 1.20\n",
              "Forward/backward pass size (MB): 237.78\n",
              "Params size (MB): 574.67\n",
              "Estimated Total Size (MB): 813.65\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2,3,224,224)\n",
        "print(model(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rb4rnOey2rC",
        "outputId": "5a916470-bc7b-45a8-db61-395311be9a90"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    }
  ]
}