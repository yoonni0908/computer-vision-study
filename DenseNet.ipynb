{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSAb182TR3IH6qxrjyHyRZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hsi-cwKf9wBM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, k):\n",
        "        super().__init__()\n",
        "\n",
        "        self.residual = nn.Sequential(nn.BatchNorm2d(in_channels),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels, 4*k, kernel_size=1, bias=False),\n",
        "                                      nn.BatchNorm2d(4*k),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(4*k, k, kernel_size=3, padding=1, bias=False))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([x, self.residual(x)], 1) # x가 바로 직전 채널 뿐만 아니라 그 전것도 모두 가지고 있음\n",
        "\n",
        "class Transition(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.transition = nn.Sequential(nn.BatchNorm2d(in_channels),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "                                        nn.AvgPool2d(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.transition(x)\n",
        "\n",
        "#DesneNet-BC\n",
        "#B stands for bottleneck layer(BN-RELU-CONV(1x1)-BN-RELU-CONV(3x3))\n",
        "#C stands for compression factor(0< theta ≤1)\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_block_list, growth_rate, reduction=0.5, num_class=100):\n",
        "        super().__init__()\n",
        "        self.k = growth_rate\n",
        "\n",
        "        inner_channels = 2 * self.k\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, inner_channels, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "                                   nn.BatchNorm2d(inner_channels),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "        layers = []\n",
        "        for num_blocks in num_block_list[:-1]:\n",
        "            layers += [self._make_dense_layers(inner_channels, num_blocks)]\n",
        "            inner_channels += self.k * num_blocks\n",
        "\n",
        "            out_channels = int(reduction * inner_channels)\n",
        "            layers += [Transition(inner_channels, out_channels)]\n",
        "            inner_channels = out_channels\n",
        "\n",
        "        layers += [self._make_dense_layers(inner_channels, num_block_list[-1])]\n",
        "        inner_channels += self.k * num_block_list[-1]\n",
        "        layers += [nn.BatchNorm2d(inner_channels)]\n",
        "        layers += [nn.ReLU(inplace=True)]\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.linear = nn.Linear(inner_channels, num_class)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.features(output)\n",
        "        output = self.avgpool(output)\n",
        "        output = torch.flatten(output, start_dim=1)\n",
        "        output = self.linear(output)\n",
        "        return output\n",
        "\n",
        "    def _make_dense_layers(self, in_channels, nblocks):\n",
        "        dense_block = []\n",
        "        for _ in range(nblocks):\n",
        "            dense_block += [ Bottleneck(in_channels, self.k) ]\n",
        "            in_channels += self.k\n",
        "        return nn.Sequential(*dense_block)"
      ],
      "metadata": {
        "id": "A-bPVswl9xqf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def densenet121(**kwargs):\n",
        "    return DenseNet([6,12,24,16], growth_rate=32, **kwargs)\n",
        "\n",
        "def densenet169(**kwargs):\n",
        "    return DenseNet([6,12,32,32], growth_rate=32, **kwargs)\n",
        "\n",
        "def densenet201(**kwargs):\n",
        "    return DenseNet([6,12,48,32], growth_rate=32, **kwargs)\n",
        "\n",
        "def densenet264(**kwargs):\n",
        "    return DenseNet([6,12,64,48], growth_rate=32, **kwargs)"
      ],
      "metadata": {
        "id": "pmCMdHREa58d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = densenet121()\n",
        "# print(model)\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "summary(model, input_size=(2,3,224,224), device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCsSvTs3a9J2",
        "outputId": "8c7606a4-cfc6-4f25-ba7e-859bf8011bf5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "DenseNet                                      [2, 100]                  --\n",
              "├─Sequential: 1-1                             [2, 64, 56, 56]           --\n",
              "│    └─Conv2d: 2-1                            [2, 64, 112, 112]         9,408\n",
              "│    └─BatchNorm2d: 2-2                       [2, 64, 112, 112]         128\n",
              "│    └─ReLU: 2-3                              [2, 64, 112, 112]         --\n",
              "│    └─MaxPool2d: 2-4                         [2, 64, 56, 56]           --\n",
              "├─Sequential: 1-2                             [2, 1024, 7, 7]           --\n",
              "│    └─Sequential: 2-5                        [2, 256, 56, 56]          --\n",
              "│    │    └─Bottleneck: 3-1                   [2, 96, 56, 56]           45,440\n",
              "│    │    └─Bottleneck: 3-2                   [2, 128, 56, 56]          49,600\n",
              "│    │    └─Bottleneck: 3-3                   [2, 160, 56, 56]          53,760\n",
              "│    │    └─Bottleneck: 3-4                   [2, 192, 56, 56]          57,920\n",
              "│    │    └─Bottleneck: 3-5                   [2, 224, 56, 56]          62,080\n",
              "│    │    └─Bottleneck: 3-6                   [2, 256, 56, 56]          66,240\n",
              "│    └─Transition: 2-6                        [2, 128, 28, 28]          --\n",
              "│    │    └─Sequential: 3-7                   [2, 128, 28, 28]          33,280\n",
              "│    └─Sequential: 2-7                        [2, 512, 28, 28]          --\n",
              "│    │    └─Bottleneck: 3-8                   [2, 160, 28, 28]          53,760\n",
              "│    │    └─Bottleneck: 3-9                   [2, 192, 28, 28]          57,920\n",
              "│    │    └─Bottleneck: 3-10                  [2, 224, 28, 28]          62,080\n",
              "│    │    └─Bottleneck: 3-11                  [2, 256, 28, 28]          66,240\n",
              "│    │    └─Bottleneck: 3-12                  [2, 288, 28, 28]          70,400\n",
              "│    │    └─Bottleneck: 3-13                  [2, 320, 28, 28]          74,560\n",
              "│    │    └─Bottleneck: 3-14                  [2, 352, 28, 28]          78,720\n",
              "│    │    └─Bottleneck: 3-15                  [2, 384, 28, 28]          82,880\n",
              "│    │    └─Bottleneck: 3-16                  [2, 416, 28, 28]          87,040\n",
              "│    │    └─Bottleneck: 3-17                  [2, 448, 28, 28]          91,200\n",
              "│    │    └─Bottleneck: 3-18                  [2, 480, 28, 28]          95,360\n",
              "│    │    └─Bottleneck: 3-19                  [2, 512, 28, 28]          99,520\n",
              "│    └─Transition: 2-8                        [2, 256, 14, 14]          --\n",
              "│    │    └─Sequential: 3-20                  [2, 256, 14, 14]          132,096\n",
              "│    └─Sequential: 2-9                        [2, 1024, 14, 14]         --\n",
              "│    │    └─Bottleneck: 3-21                  [2, 288, 14, 14]          70,400\n",
              "│    │    └─Bottleneck: 3-22                  [2, 320, 14, 14]          74,560\n",
              "│    │    └─Bottleneck: 3-23                  [2, 352, 14, 14]          78,720\n",
              "│    │    └─Bottleneck: 3-24                  [2, 384, 14, 14]          82,880\n",
              "│    │    └─Bottleneck: 3-25                  [2, 416, 14, 14]          87,040\n",
              "│    │    └─Bottleneck: 3-26                  [2, 448, 14, 14]          91,200\n",
              "│    │    └─Bottleneck: 3-27                  [2, 480, 14, 14]          95,360\n",
              "│    │    └─Bottleneck: 3-28                  [2, 512, 14, 14]          99,520\n",
              "│    │    └─Bottleneck: 3-29                  [2, 544, 14, 14]          103,680\n",
              "│    │    └─Bottleneck: 3-30                  [2, 576, 14, 14]          107,840\n",
              "│    │    └─Bottleneck: 3-31                  [2, 608, 14, 14]          112,000\n",
              "│    │    └─Bottleneck: 3-32                  [2, 640, 14, 14]          116,160\n",
              "│    │    └─Bottleneck: 3-33                  [2, 672, 14, 14]          120,320\n",
              "│    │    └─Bottleneck: 3-34                  [2, 704, 14, 14]          124,480\n",
              "│    │    └─Bottleneck: 3-35                  [2, 736, 14, 14]          128,640\n",
              "│    │    └─Bottleneck: 3-36                  [2, 768, 14, 14]          132,800\n",
              "│    │    └─Bottleneck: 3-37                  [2, 800, 14, 14]          136,960\n",
              "│    │    └─Bottleneck: 3-38                  [2, 832, 14, 14]          141,120\n",
              "│    │    └─Bottleneck: 3-39                  [2, 864, 14, 14]          145,280\n",
              "│    │    └─Bottleneck: 3-40                  [2, 896, 14, 14]          149,440\n",
              "│    │    └─Bottleneck: 3-41                  [2, 928, 14, 14]          153,600\n",
              "│    │    └─Bottleneck: 3-42                  [2, 960, 14, 14]          157,760\n",
              "│    │    └─Bottleneck: 3-43                  [2, 992, 14, 14]          161,920\n",
              "│    │    └─Bottleneck: 3-44                  [2, 1024, 14, 14]         166,080\n",
              "│    └─Transition: 2-10                       [2, 512, 7, 7]            --\n",
              "│    │    └─Sequential: 3-45                  [2, 512, 7, 7]            526,336\n",
              "│    └─Sequential: 2-11                       [2, 1024, 7, 7]           --\n",
              "│    │    └─Bottleneck: 3-46                  [2, 544, 7, 7]            103,680\n",
              "│    │    └─Bottleneck: 3-47                  [2, 576, 7, 7]            107,840\n",
              "│    │    └─Bottleneck: 3-48                  [2, 608, 7, 7]            112,000\n",
              "│    │    └─Bottleneck: 3-49                  [2, 640, 7, 7]            116,160\n",
              "│    │    └─Bottleneck: 3-50                  [2, 672, 7, 7]            120,320\n",
              "│    │    └─Bottleneck: 3-51                  [2, 704, 7, 7]            124,480\n",
              "│    │    └─Bottleneck: 3-52                  [2, 736, 7, 7]            128,640\n",
              "│    │    └─Bottleneck: 3-53                  [2, 768, 7, 7]            132,800\n",
              "│    │    └─Bottleneck: 3-54                  [2, 800, 7, 7]            136,960\n",
              "│    │    └─Bottleneck: 3-55                  [2, 832, 7, 7]            141,120\n",
              "│    │    └─Bottleneck: 3-56                  [2, 864, 7, 7]            145,280\n",
              "│    │    └─Bottleneck: 3-57                  [2, 896, 7, 7]            149,440\n",
              "│    │    └─Bottleneck: 3-58                  [2, 928, 7, 7]            153,600\n",
              "│    │    └─Bottleneck: 3-59                  [2, 960, 7, 7]            157,760\n",
              "│    │    └─Bottleneck: 3-60                  [2, 992, 7, 7]            161,920\n",
              "│    │    └─Bottleneck: 3-61                  [2, 1024, 7, 7]           166,080\n",
              "│    └─BatchNorm2d: 2-12                      [2, 1024, 7, 7]           2,048\n",
              "│    └─ReLU: 2-13                             [2, 1024, 7, 7]           --\n",
              "├─AdaptiveAvgPool2d: 1-3                      [2, 1024, 1, 1]           --\n",
              "├─Linear: 1-4                                 [2, 100]                  102,500\n",
              "===============================================================================================\n",
              "Total params: 7,056,356\n",
              "Trainable params: 7,056,356\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 5.67\n",
              "===============================================================================================\n",
              "Input size (MB): 1.20\n",
              "Forward/backward pass size (MB): 361.07\n",
              "Params size (MB): 28.23\n",
              "Estimated Total Size (MB): 390.50\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2,3,224,224)\n",
        "print(model(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYYAce91bBsw",
        "outputId": "a8a417cd-1e8d-4372-863d-77aad55affda"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 100])\n"
          ]
        }
      ]
    }
  ]
}